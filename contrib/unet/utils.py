import torch


def cosanneal_lr_adam(lit_mod, lr, T_max=100, weight_decay=0.0):
    opt = torch.optim.Adam(
        [
            {"params": lit_mod.parameters(), "lr": lr},
        ],
        weight_decay=weight_decay,
    )
    return {
        "optimizer": opt,
        "lr_scheduler": torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=T_max),
    }
